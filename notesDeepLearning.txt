#
To define deep learning and understand the difference between deep learning
and other machine-learning approaches, first we need some idea of what machine-
learning algorithms do. I just stated that machine learning discovers rules to execute
a data-processing task, given examples of what’s expected. So, to do machine learn-
ing, we need three things:
	>Input data points—For instance, if the task is speech recognition, these data
points could be sound files of people speaking. If the task is image tagging,
they could be pictures.
	>Examples of the expected output—In a speech-recognition task, these could be
human-generated transcripts of sound files. In an image task, expected outputs
could be tags such as “dog,” “cat,” and so on.
	>A way to measure whether the algorithm is doing a good job—This is necessary in
order to determine the distance between the algorithm’s current output and
its expected output. The measurement is used as a feedback signal to adjust
the way the algorithm works. This adjustment step is what we call learning.

#
https://www.kaggle.com/

#
https://developer.nvidia.com/about-cuda

#
The problem we’re trying to solve here is to classify grayscale images of handwritten digits (28 × 28 pixels) 
into their 10 categories (0 through 9). We’ll use the MNIST dataset, a classic in the machine-learning community, 
which has been around almost as long as the field itself and has been intensively studied. It’s a set of 60,000 training
images, plus 10,000 test images, assembled by the National Institute of Standards and
Technology (the NIST in MNIST ) in the 1980s. You can think of “solving” MNIST as the “Hello World” of deep learning.

#
Note on classes and labels:-
In machine learning, a category in a classification problem is called a class.
Data points are called samples. The class associated with a specific sample is called a label.

#
Loading the MNIST dataset in Keras:-
from keras.datasets import mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

* train_images and train_labels form the training set, the data that the model will
learn from. The model will then be tested on the test set, test_images and test_labels.

The images are encoded as Numpy arrays, and the labels are an array of digits, ranging
from 0 to 9. The images and labels have a one-to-one correspondence.
Let’s look at the training data:
>>> train_images.shape
(60000, 28, 28)
>>> len(train_labels)
60000
>>> train_labels
array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)
And here’s the test data:
>>> test_images.shape
(10000, 28, 28)
>>> len(test_labels)
10000
>>> test_labels
array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)

* The workflow will be as follows: First, we’ll feed the neural network the training data,
train_images and train_labels . The network will then learn to associate images and
labels. Finally, we’ll ask the network to produce predictions for test_images , and we’ll
verify whether these predictions match the labels from test_labels .

#
The core building block of neural networks is the layer, a data-processing module that
you can think of as a filter for data.

#
The network architecture:-

from keras import models
from keras import layers
network = models.Sequential()
network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))
network.add(layers.Dense(10, activation='softmax'))

* Here, our network consists of a sequence of two Dense layers, which are densely
connected (also called fully connected) neural layers. The second (and last) layer is a
10-way softmax layer, which means it will return an array of 10 probability scores (sum-
ming to 1). Each score will be the probability that the current digit image belongs to
one of our 10 digit classes.

To make the network ready for training, we need to pick three more things, as part
of the compilation step:
	A loss function—How the network will be able to measure its performance on
the training data, and thus how it will be able to steer itself in the right direc-
tion.

	An optimizer—The mechanism through which the network will update itself
based on the data it sees and its loss function.

	Metrics to monitor during training and testing—Here, we’ll only care about accu-
racy (the fraction of the images that were correctly classified).

The compilation step:-

network.compile(optimizer='rmsprop',
loss='categorical_crossentropy',
metrics=['accuracy'])

* Before training, we’ll preprocess the data by reshaping it into the shape the network
expects and scaling it so that all values are in the [0, 1] interval. Previously, our train-
ing images, for instance, were stored in an array of shape (60000, 28, 28) of type
uint8 with values in the [0, 255] interval. We transform it into a float32 array of
shape (60000, 28 * 28) with values between 0 and 1.

Preparing the image data:-
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype('float32') / 255

We also need to categorically encode the labels, a step that’s explained in chapter 3.

Preparing the labels:-
from keras.utils import to_categorical
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

We’re now ready to train the network, which in Keras is done via a call to the net-
work’s fit method—we fit the model to its training data:

network.fit(train_images, train_labels, epochs=5, batch_size=128)

Epoch 1/5
60000/60000 [==============================] - 9s - loss: 0.2524 - acc: 0.9273
Epoch 2/5
51328/60000 [========================>.....] - ETA: 1s - loss: 0.1035 - acc: 0.9692

Two quantities are displayed during training: the loss of the network over the training
data, and the accuracy of the network over the training data.

We quickly reach an accuracy of 0.989 (98.9%) on the training data. Now let’s
check that the model performs well on the test set, too:

test_loss, test_acc = network.evaluate(test_images, test_labels)
print('test_acc:', test_acc)
test_acc: 0.9785


The test-set accuracy turns out to be 97.8%—that’s quite a bit lower than the training
set accuracy. This gap between training accuracy and test accuracy is an example of
overfitting: the fact that machine-learning models tend to perform worse on new data
than on their training data. Overfitting is a central topic in chapter 3.


